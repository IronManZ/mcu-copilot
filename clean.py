#!/usr/bin/env python3
"""
MCU-Copilot é¡¹ç›®æ¸…ç†å·¥å…·
ç±»ä¼¼äº gradle cleanï¼Œæ¸…ç†é¡¹ç›®ä¸­çš„ä¸´æ—¶æ–‡ä»¶å’Œæ„å»ºäº§ç‰©
"""

import os
import shutil
import glob
import argparse
from pathlib import Path
from typing import List, Set
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ProjectCleaner:
    """é¡¹ç›®æ¸…ç†å™¨"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.cleaned_files = 0
        self.cleaned_dirs = 0
        self.freed_space = 0

    def get_patterns_to_clean(self) -> dict:
        """å®šä¹‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶å’Œç›®å½•æ¨¡å¼"""
        return {
            "python_cache": {
                "patterns": ["**/__pycache__", "**/*.pyc", "**/*.pyo", "**/*.pyd"],
                "description": "Pythonç¼“å­˜æ–‡ä»¶"
            },
            "logs": {
                "patterns": ["**/logs/*.log", "**/logs/*.jsonl", "**/*.log"],
                "description": "æ—¥å¿—æ–‡ä»¶",
                "keep_recent": 3  # ä¿ç•™æœ€è¿‘3ä¸ªæ–‡ä»¶
            },
            "build_artifacts": {
                "patterns": [
                    "**/dist", "**/build", "**/.coverage",
                    "**/coverage", "**/.pytest_cache", "**/.cache"
                ],
                "description": "æ„å»ºäº§ç‰©",
                "exclude": ["**/node_modules/**"]  # ä¿ç•™node_modulesä¸­çš„æ„å»ºäº§ç‰©
            },
            "temp_files": {
                "patterns": [
                    "**/.DS_Store", "**/*.tmp", "**/*.temp",
                    "**/Thumbs.db", "**/._.DS_Store"
                ],
                "description": "ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶"
            },
            "test_outputs": {
                "patterns": [
                    "**/*_test_report_*.html", "**/test_output_*.html",
                    "**/debug_*.py", "**/quick_*.py", "**/test_*.py"
                ],
                "description": "æµ‹è¯•è¾“å‡ºæ–‡ä»¶",
                "exclude": ["**/tests/**", "**/test/**"]  # æ’é™¤æ­£å¼æµ‹è¯•ç›®å½•
            },
            "node_artifacts": {
                "patterns": [
                    "**/node_modules/.cache", "**/.vite", "**/.turbo",
                    "**/dist", "**/.next", "**/.nuxt"
                ],
                "description": "Node.jsæ„å»ºäº§ç‰©",
                "exclude": ["**/node_modules/**"]  # å®Œå…¨ä¿ç•™node_moduleså†…å®¹
            },
            "docker_temp": {
                "patterns": ["**/.env.temp", "**/*.pid", "**/docker-compose.override.yml"],
                "description": "Dockerä¸´æ—¶æ–‡ä»¶"
            }
        }

    def get_file_size(self, path: Path) -> int:
        """è·å–æ–‡ä»¶æˆ–ç›®å½•å¤§å°"""
        if path.is_file():
            return path.stat().st_size
        elif path.is_dir():
            return sum(f.stat().st_size for f in path.rglob('*') if f.is_file())
        return 0

    def should_exclude(self, path: Path, exclude_patterns: List[str]) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
        if not exclude_patterns:
            return False

        for pattern in exclude_patterns:
            if path.match(pattern) or any(parent.match(pattern.replace('**/', ''))
                                        for parent in path.parents):
                return True
        return False

    def clean_by_patterns(self, patterns: List[str], exclude_patterns: List[str] = None) -> List[Path]:
        """æ ¹æ®æ¨¡å¼æ¸…ç†æ–‡ä»¶"""
        cleaned_paths = []
        exclude_patterns = exclude_patterns or []

        for pattern in patterns:
            for path in self.project_root.glob(pattern):
                if self.should_exclude(path, exclude_patterns):
                    continue

                if path.exists():
                    size = self.get_file_size(path)
                    self.freed_space += size

                    if path.is_file():
                        path.unlink()
                        self.cleaned_files += 1
                        logger.debug(f"åˆ é™¤æ–‡ä»¶: {path.relative_to(self.project_root)}")
                    elif path.is_dir():
                        shutil.rmtree(path)
                        self.cleaned_dirs += 1
                        logger.debug(f"åˆ é™¤ç›®å½•: {path.relative_to(self.project_root)}")

                    cleaned_paths.append(path)

        return cleaned_paths

    def clean_logs_with_retention(self, patterns: List[str], keep_recent: int = 3):
        """æ¸…ç†æ—¥å¿—æ–‡ä»¶ï¼Œä¿ç•™æœ€è¿‘çš„å‡ ä¸ª"""
        log_files = []

        for pattern in patterns:
            for path in self.project_root.glob(pattern):
                if path.is_file() and path.exists():
                    log_files.append((path, path.stat().st_mtime))

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„å‡ ä¸ª
        log_files.sort(key=lambda x: x[1], reverse=True)

        for path, _ in log_files[keep_recent:]:
            size = self.get_file_size(path)
            self.freed_space += size
            path.unlink()
            self.cleaned_files += 1
            logger.debug(f"åˆ é™¤æ—§æ—¥å¿—: {path.relative_to(self.project_root)}")

    def clean_category(self, category: str, config: dict):
        """æ¸…ç†ç‰¹å®šç±»åˆ«çš„æ–‡ä»¶"""
        logger.info(f"ğŸ§¹ æ¸…ç† {config['description']}...")

        if category == "logs" and "keep_recent" in config:
            self.clean_logs_with_retention(config["patterns"], config["keep_recent"])
        else:
            self.clean_by_patterns(
                config["patterns"],
                config.get("exclude", [])
            )

    def clean_all(self, categories: Set[str] = None):
        """æ‰§è¡Œå®Œæ•´æ¸…ç†"""
        logger.info(f"ğŸš€ å¼€å§‹æ¸…ç†é¡¹ç›®: {self.project_root}")

        patterns_config = self.get_patterns_to_clean()
        categories = categories or set(patterns_config.keys())

        for category in categories:
            if category in patterns_config:
                self.clean_category(category, patterns_config[category])

        # æ¸…ç†ç©ºç›®å½•
        self._clean_empty_dirs()

        logger.info(f"âœ… æ¸…ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š åˆ é™¤æ–‡ä»¶: {self.cleaned_files} ä¸ª")
        logger.info(f"ğŸ“Š åˆ é™¤ç›®å½•: {self.cleaned_dirs} ä¸ª")
        logger.info(f"ğŸ’¾ é‡Šæ”¾ç©ºé—´: {self._format_size(self.freed_space)}")

    def _clean_empty_dirs(self):
        """æ¸…ç†ç©ºç›®å½•"""
        for root, dirs, files in os.walk(self.project_root, topdown=False):
            for dirname in dirs:
                dir_path = Path(root) / dirname
                try:
                    if dir_path.exists() and not any(dir_path.iterdir()):
                        # è·³è¿‡é‡è¦çš„ç©ºç›®å½•
                        if dirname not in ['logs', 'dist', 'build', '__pycache__']:
                            dir_path.rmdir()
                            self.cleaned_dirs += 1
                            logger.debug(f"åˆ é™¤ç©ºç›®å½•: {dir_path.relative_to(self.project_root)}")
                except (OSError, PermissionError):
                    pass

    def _format_size(self, size: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"

    def dry_run(self, categories: Set[str] = None):
        """æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶"""
        logger.info("ğŸ” æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")

        patterns_config = self.get_patterns_to_clean()
        categories = categories or set(patterns_config.keys())

        total_files = 0
        total_size = 0

        for category in categories:
            if category not in patterns_config:
                continue

            config = patterns_config[category]
            logger.info(f"ğŸ” æ£€æŸ¥ {config['description']}...")

            found_files = []
            for pattern in config["patterns"]:
                for path in self.project_root.glob(pattern):
                    if self.should_exclude(path, config.get("exclude", [])):
                        continue
                    if path.exists():
                        size = self.get_file_size(path)
                        found_files.append((path, size))
                        total_size += size

            if found_files:
                total_files += len(found_files)
                logger.info(f"  æ‰¾åˆ° {len(found_files)} ä¸ªæ–‡ä»¶/ç›®å½•")
                for path, size in found_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    logger.info(f"    - {path.relative_to(self.project_root)} ({self._format_size(size)})")
                if len(found_files) > 5:
                    logger.info(f"    ... è¿˜æœ‰ {len(found_files) - 5} ä¸ª")

        logger.info(f"ğŸ“Š æ€»è®¡: {total_files} ä¸ªæ–‡ä»¶/ç›®å½•, {self._format_size(total_size)}")


def main():
    parser = argparse.ArgumentParser(description="MCU-Copilot é¡¹ç›®æ¸…ç†å·¥å…·")
    parser.add_argument("--dry-run", "-n", action="store_true",
                       help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶")
    parser.add_argument("--categories", "-c", nargs="+",
                       choices=["python_cache", "logs", "build_artifacts",
                               "temp_files", "test_outputs", "node_artifacts", "docker_temp"],
                       help="æŒ‡å®šè¦æ¸…ç†çš„ç±»åˆ«")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    cleaner = ProjectCleaner()
    categories = set(args.categories) if args.categories else None

    if args.dry_run:
        cleaner.dry_run(categories)
    else:
        cleaner.clean_all(categories)


if __name__ == "__main__":
    main()